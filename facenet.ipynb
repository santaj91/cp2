{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facenet.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Bf88bfdIYEJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgFMbC6QXAMw"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/keras-facenet/model/facenet_keras.h5')\n",
        "\n",
        "print(model.inputs)\n",
        "print(model.outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mtcnn"
      ],
      "metadata": {
        "id": "o27c5s7RY6Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras_facenet"
      ],
      "metadata": {
        "id": "UaDskEPbjEU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fileinput import filename\n",
        "import os\n",
        "from os import listdir\n",
        "import scipy\n",
        "import cv2\n",
        "import dlib \n",
        "import numpy as np\n",
        "from PIL import Image # 이미지 크기 조정 라이브러리\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf \n",
        "from mtcnn.mtcnn import MTCNN #불러온 사진에 얼굴 감자히는 '얼굴 감지기'라이브러리\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras_facenet import FaceNet\n",
        "from tensorflow.keras.models import Model\n",
        "from numpy import savez_compressed"
      ],
      "metadata": {
        "id": "1b66Vd0Ai_sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_face(filename, required_size=(160, 160)):\n",
        "\timage = Image.open(filename)\n",
        "\timage = image.convert('RGB')\n",
        "\tpixels = np.asarray(image)# 배열로 변환\n",
        "\tdetector = MTCNN()# 감지기 생성, 기본 가중치 이용\n",
        "\tresults = detector.detect_faces(pixels)# 이미지에서 얼굴 감지\n",
        "\tx1, y1, width, height = results[0]['box']# 첫 번째 얼굴에서 경계 상자 추출\n",
        "\t# 버그 수정\n",
        "\tx1, y1 = abs(x1), abs(y1)\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# 얼굴 추출\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# 모델 사이즈로 픽셀 재조정\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = np.asarray(image)\n",
        "\treturn face_array"
      ],
      "metadata": {
        "id": "J4F2BFQpjMEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder = '/content/drive/MyDrive/facedataset/train/'\n",
        "i = 1"
      ],
      "metadata": {
        "id": "DFKqwXPIjP9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디렉토리 안의 모든 이미지를 불러오고 이미지에서 얼굴 추출\n",
        "def load_faces(directory):\n",
        "\tfaces = list()\n",
        "\t# 파일 열거\n",
        "\tfor filename in listdir(directory):\n",
        "\t\t# 경로\n",
        "\t\tpath = directory + filename\n",
        "\t\t# 얼굴 추출\n",
        "\t\tface = extract_face(path)\n",
        "\t\t# 저장\n",
        "\t\tfaces.append(face)\n",
        "\treturn faces"
      ],
      "metadata": {
        "id": "oofQf595jf14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 포함하는 각 클래스에 대해 하나의 하위 디렉토리가 포함된 데이터셋을 불러오기\n",
        "def load_dataset(directory):\n",
        "\tX, y = list(), list()\n",
        "\t# 클래스별로 폴더 열거\n",
        "\tfor subdir in listdir(directory):\n",
        "\t\t# 경로\n",
        "\t\tpath = directory + subdir + '/'\n",
        "\t\t# 디렉토리에 있을 수 있는 파일을 건너뛰기(디렉토리가 아닌 파일)\n",
        "\t\tif not os.path.isdir(path):\n",
        "\t\t\tcontinue\n",
        "\t\t# 하위 디렉토리의 모든 얼굴 불러오기\n",
        "\t\tfaces = load_faces(path)\n",
        "\t\t# 레이블 생성\n",
        "\t\tlabels = [subdir for _ in range(len(faces))]\n",
        "\t\t# 진행 상황 요약\n",
        "\t\tprint('>%d개의 예제를 불러왔습니다. 클래스명: %s' % (len(faces), subdir))\n",
        "\t\t# 저장\n",
        "\t\tX.extend(faces)\n",
        "\t\ty.extend(labels)\n",
        "\treturn np.asarray(X), np.asarray(y)"
      ],
      "metadata": {
        "id": "y5l0LFx5ji2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터셋 불러오기\n",
        "trainX, trainy = load_dataset('/content/drive/MyDrive/facedataset/train/')\n",
        "print(trainX.shape, trainy.shape)\n",
        "# 테스트 데이터셋 불러오기\n",
        "testX, testy = load_dataset('/content/drive/MyDrive/facedataset/test/')\n",
        "print(testX.shape, testy.shape)\n",
        "# 배열을 단일 압축 포맷 파일로 저장\n",
        "np.savez_compressed('3-celebrity-faces-dataset.npz', trainX, trainy, testX, testy)\n",
        "\n",
        "data = np.load('3-celebrity-faces-dataset.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "print('불러오기: ', trainX.shape, trainy.shape, testX.shape, testy.shape)"
      ],
      "metadata": {
        "id": "ipLfeEIsjl4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "8MJD8dy4lda-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import expand_dims\n",
        "# 하나의 얼굴의 얼굴 임베딩 얻기\n",
        "def get_embedding(model, face_pixels):\n",
        "\t# 픽셀 값의 척도\n",
        "\tface_pixels = face_pixels.astype('int32')\n",
        "\t# 채널 간 픽셀값 표준화(전역에 걸쳐)\n",
        "\tmean, std = face_pixels.mean(), face_pixels.std()\n",
        "\tface_pixels = (face_pixels - mean) / std\n",
        "\t# 얼굴을 하나의 샘플로 변환\n",
        "\tsamples = expand_dims(face_pixels, axis=0)\n",
        "\t# 임베딩을 갖기 위한 예측 생성\n",
        "\tyhat = model.predict(samples)\n",
        "\treturn yhat[0]"
      ],
      "metadata": {
        "id": "ImewUXIFjzvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 셋에서 각 얼굴을 임베딩으로 변환하기\n",
        "newTrainX = list()\n",
        "for face_pixels in trainX:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnewTrainX.append(embedding)\n",
        "newTrainX = np.asarray(newTrainX)\n",
        "print(newTrainX.shape)\n",
        "# 테스트 셋에서 각 얼굴을 임베딩으로 변환하기\n",
        "newTestX = list()\n",
        "for face_pixels in testX:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnewTestX.append(embedding)\n",
        "newTestX = np.asarray(newTestX)\n",
        "print(newTestX.shape)\n",
        "# 배열을 하나의 압축 포맷 파일로 저장\n",
        "np.savez_compressed('3-celebrity-faces-embeddings.npz', newTrainX, trainy, newTestX, testy)"
      ],
      "metadata": {
        "id": "Y1fi9JSvkL_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing# 3명의 유명인사 얼굴 데이터셋으로 분류기 개발\n",
        "from numpy import load\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "data = load('/content/3-celebrity-faces-embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "print('데이터셋: 훈련 %d개, 테스트 %d개' % (trainX.shape[0], testX.shape[0]))\n",
        "# 입력 벡터 일반화\n",
        "in_encoder = Normalizer(norm='l2') #유클리디안 거리=ㅣ2\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "# 목표 레이블 암호화\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "# 모델 맞추기(적합시키기)\n",
        "classifier= svm.SVC(kernel='linear', probability=True)\n",
        "classifier.fit(trainX, trainy)\n",
        "# 유클리디안으로 거리로 찾을땐 정확도가 높아지는지 확인\n",
        "# 추측\n",
        "yhat_train = classifier.predict(trainX)\n",
        "yhat_test = classifier.predict(testX)\n",
        "# 정확도 점수\n",
        "score_train = accuracy_score(trainy, yhat_train)\n",
        "score_test = accuracy_score(testy, yhat_test)\n",
        "# 요약\n",
        "print('정확도: 훈련=%.3f, 테스트=%.3f' % (score_train*100, score_test*100))"
      ],
      "metadata": {
        "id": "yKUb9pCvkhAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 얼굴 불러오기\n",
        "data = load('3-celebrity-faces-dataset.npz')\n",
        "testX_faces = data['arr_2']\n",
        "\n",
        "# 테스트 데이터셋에서 임의의 예제에 대한 테스트 모델\n",
        "from random import choice\n",
        "selection = choice([i for i in range(testX.shape[0])])\n",
        "random_face_pixels = testX_faces[selection]\n",
        "random_face_emb = testX[selection]\n",
        "random_face_class = testy[selection]\n",
        "random_face_name = out_encoder.inverse_transform([random_face_class])\n",
        "# 얼굴 예측\n",
        "samples = expand_dims(random_face_emb, axis=0)\n",
        "yhat_class = classifier.predict(samples)\n",
        "yhat_prob = classifier.predict_proba(samples)\n",
        "# 이름 얻기\n",
        "class_index = yhat_class[0]\n",
        "class_probability = yhat_prob[0,class_index] * 100\n",
        "predict_names = out_encoder.inverse_transform(yhat_class)\n",
        "print('예상: %s (%.3f)' % (predict_names[0], class_probability))\n",
        "print('추측: %s' % random_face_name[0])\n",
        "# 재미삼아 그리기\n",
        "plt.imshow(random_face_pixels)\n",
        "title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
        "plt.title(title)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4nRUTVU3k3Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(classifier, './classifier.pkl')"
      ],
      "metadata": {
        "id": "VgbAgMgWXFLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(out_encoder, './out_encoder.pkl')"
      ],
      "metadata": {
        "id": "VFW0xdPJyFvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask"
      ],
      "metadata": {
        "id": "BRtsQIUN1am5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/keras-facenet/model/facenet_keras.h5')\n",
        "classifier = joblib.load('/content/classifier.pkl')\n",
        "out_encoder = joblib.load('/content/out_encoder.pkl')"
      ],
      "metadata": {
        "id": "IPdd_ETAgZoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from flask_ngrok import run_with_ngrok\n",
        "# app = Flask(__name__)\n",
        "# run_with_ngrok(app)\n",
        "# @app.route('/', method=['POST']\n",
        "# def predict():\n",
        "#   if request.method == 'POST':\n",
        "#       file = requests.files.get('/content/drive/MyDrive/facedataset/test/김희애/김희애test.jpg', '')\n",
        "#       img_bytes = file.read()\n",
        "#       img = io.BytesIO(img_bytes)\n",
        "\n",
        "#       # 얼굴 영역 추출\n",
        "#       face = extract_face(img)\n",
        "#       # 임베딩벡터로 변환\n",
        "#       embedding = get_embedding(model, face_pixels)\n",
        "\n",
        "#       # classifier입력을 위한 전처리\n",
        "#       embedding = preprocess_something(embedding)\n",
        "\n",
        "#       # 결과\n",
        "#       output = dict()\n",
        "#       yhat = classifier.predict(embedding)\n",
        "#       output['label'] = out_encoder.inverse_transform(yhat)[0]\n",
        "\n",
        "#       output['prob'] = classifier.predict_prob(embedding)\n",
        "\n",
        "#       ret_img = draw_result(img)\n",
        "#       ret_bytes = io.BytesIO()\n",
        "#       ret_img.save(ret_bytes, format='PNG')\n",
        "#       output['retImg'] = base64.encodebytes(ret_bytes.getvalue()).decode('ascii')\n",
        "#     return jsonify(output)"
      ],
      "metadata": {
        "id": "pZ1K4X9pyPs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install flask-ngrok\n",
        "# from flask import Flask, url_for, redirect, render_template, request\n",
        "# from flask_ngrok import run_with_ngrok\n",
        "# import os\n",
        "\n",
        "# app = Flask(__name__)\n",
        "# run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "# @app.route('/')\n",
        "# def index():\n",
        "#     return render_template('index.html')  # Start ngrok when app is run\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     app.run()"
      ],
      "metadata": {
        "id": "gGKKupD52_K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dSoEPhsv5Fxy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}